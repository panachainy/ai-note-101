{
    "id": "956f0b67-9c18-4275-8bf5-dd4024590b82",
    "data": {
      "nodes": [
        {
          "width": 384,
          "height": 629,
          "id": "ChatOpenAI-qdmsI",
          "type": "genericNode",
          "position": {
            "x": 241.3279963280445,
            "y": -486.8439112212181
          },
          "data": {
            "type": "ChatOpenAI",
            "node": {
              "template": {
                "callbacks": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "callbacks",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "langchain.callbacks.base.BaseCallbackHandler",
                  "list": true
                },
                "cache": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "cache",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "bool",
                  "list": false
                },
                "client": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "client",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "Any",
                  "list": false
                },
                "max_retries": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": 6,
                  "password": false,
                  "name": "max_retries",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "int",
                  "list": false
                },
                "max_tokens": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": true,
                  "name": "max_tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "int",
                  "list": false,
                  "value": ""
                },
                "metadata": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "metadata",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "dict",
                  "list": false
                },
                "model_kwargs": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "model_kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "type": "dict",
                  "list": false
                },
                "model_name": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "value": "gpt-3.5-turbo",
                  "password": false,
                  "options": [
                    "gpt-3.5-turbo-0613",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-16k-0613",
                    "gpt-3.5-turbo-16k",
                    "gpt-4-0613",
                    "gpt-4-32k-0613",
                    "gpt-4",
                    "gpt-4-32k"
                  ],
                  "name": "model_name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": true
                },
                "n": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": 1,
                  "password": false,
                  "name": "n",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "int",
                  "list": false
                },
                "openai_api_base": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": false,
                  "dynamic": false,
                  "info": "\nThe base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.\n",
                  "type": "str",
                  "list": false
                },
                "openai_api_key": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "password": true,
                  "name": "openai_api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "openai_organization": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "openai_organization",
                  "display_name": "OpenAI Organization",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "openai_proxy": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "openai_proxy",
                  "display_name": "OpenAI Proxy",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "request_timeout": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "request_timeout",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "float",
                  "list": false,
                  "value": 60
                },
                "streaming": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "password": false,
                  "name": "streaming",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "bool",
                  "list": false
                },
                "tags": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "tags",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": true
                },
                "temperature": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "value": 0.7,
                  "password": false,
                  "name": "temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "float",
                  "list": false
                },
                "tiktoken_model_name": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "tiktoken_model_name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "verbose": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "password": false,
                  "name": "verbose",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "bool",
                  "list": false
                },
                "_type": "ChatOpenAI"
              },
              "description": "`OpenAI` Chat large language models API.",
              "base_classes": [
                "ChatOpenAI",
                "BaseChatModel",
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "display_name": "ChatOpenAI",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/integrations/openai"
            },
            "id": "ChatOpenAI-qdmsI",
            "value": null
          },
          "selected": true,
          "dragging": false,
          "positionAbsolute": {
            "x": 241.3279963280445,
            "y": -486.8439112212181
          }
        },
        {
          "width": 384,
          "height": 577,
          "id": "ConversationBufferMemory-frtJG",
          "type": "genericNode",
          "position": {
            "x": 240.68758111624516,
            "y": 172.4355109349313
          },
          "data": {
            "type": "ConversationBufferMemory",
            "node": {
              "template": {
                "chat_memory": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "chat_memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "BaseChatMessageHistory",
                  "list": false
                },
                "ai_prefix": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": "AI",
                  "password": false,
                  "name": "ai_prefix",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "human_prefix": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": "Human",
                  "password": false,
                  "name": "human_prefix",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "input_key": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "password": false,
                  "name": "input_key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The variable to be used as Chat Input when more than one variable is available.",
                  "type": "str",
                  "list": false
                },
                "memory_key": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "value": "history",
                  "password": false,
                  "name": "memory_key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "output_key": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "password": false,
                  "name": "output_key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)",
                  "type": "str",
                  "list": false
                },
                "return_messages": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "return_messages",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "bool",
                  "list": false
                },
                "_type": "ConversationBufferMemory"
              },
              "description": "Buffer for storing conversation memory.",
              "base_classes": [
                "ConversationBufferMemory",
                "BaseChatMemory",
                "BaseMemory"
              ],
              "display_name": "ConversationBufferMemory",
              "documentation": "https://python.langchain.com/docs/modules/memory/how_to/buffer"
            },
            "id": "ConversationBufferMemory-frtJG",
            "value": null
          },
          "selected": false,
          "positionAbsolute": {
            "x": 240.68758111624516,
            "y": 172.4355109349313
          },
          "dragging": false
        },
        {
          "width": 384,
          "height": 469,
          "id": "PromptTemplate-mrNIG",
          "type": "genericNode",
          "position": {
            "x": 249.637230371315,
            "y": 756.3732210160607
          },
          "data": {
            "type": "PromptTemplate",
            "node": {
              "template": {
                "output_parser": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "output_parser",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "BaseOutputParser",
                  "list": false
                },
                "input_variables": {
                  "required": true,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "input_variables",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": true,
                  "value": [
                    "history",
                    "text"
                  ]
                },
                "partial_variables": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "password": false,
                  "name": "partial_variables",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "dict",
                  "list": false
                },
                "template": {
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "multiline": true,
                  "password": false,
                  "name": "template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "prompt",
                  "list": false,
                  "value": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\n{history}\nHuman: {text}\nAI:"
                },
                "template_format": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": "f-string",
                  "password": false,
                  "name": "template_format",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "validate_template": {
                  "required": false,
                  "placeholder": "",
                  "show": false,
                  "multiline": false,
                  "value": true,
                  "password": false,
                  "name": "validate_template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "bool",
                  "list": false
                },
                "_type": "PromptTemplate",
                "history": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "password": false,
                  "name": "history",
                  "display_name": "history",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                },
                "text": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "password": false,
                  "name": "text",
                  "display_name": "text",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "type": "str",
                  "list": false
                }
              },
              "description": "A prompt template for a language model.",
              "base_classes": [
                "StringPromptTemplate",
                "PromptTemplate",
                "BasePromptTemplate"
              ],
              "name": "",
              "display_name": "PromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/",
              "custom_fields": {
                "": [
                  "history",
                  "text"
                ],
                "template": [
                  "history",
                  "text"
                ]
              },
              "output_types": [],
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "PromptTemplate-mrNIG"
          },
          "selected": false,
          "positionAbsolute": {
            "x": 249.637230371315,
            "y": 756.3732210160607
          },
          "dragging": false
        },
        {
          "width": 384,
          "height": 339,
          "id": "LLMChain-Pvm9x",
          "type": "genericNode",
          "position": {
            "x": 1299.7208072540463,
            "y": 634.671457752373
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "code": {
                  "dynamic": true,
                  "required": true,
                  "placeholder": "",
                  "show": false,
                  "multiline": true,
                  "value": "from langflow import CustomComponent\nfrom langchain.chains import LLMChain\nfrom typing import Optional, Union, Callable\nfrom langflow.field_typing import PromptTemplate, BaseLanguageModel, BaseMemory, Chain\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: PromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "type": "code",
                  "list": false
                },
                "_type": "CustomComponent",
                "llm": {
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "BaseLanguageModel",
                  "list": false
                },
                "memory": {
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "BaseMemory",
                  "list": false
                },
                "prompt": {
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "multiline": false,
                  "password": false,
                  "name": "prompt",
                  "display_name": "Prompt",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "type": "PromptTemplate",
                  "list": false
                }
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "Chain",
                "Callable"
              ],
              "display_name": "LLMChain",
              "custom_fields": {
                "llm": null,
                "memory": null,
                "prompt": null
              },
              "output_types": [
                "LLMChain"
              ],
              "documentation": "",
              "beta": true,
              "error": null
            },
            "id": "LLMChain-Pvm9x"
          },
          "positionAbsolute": {
            "x": 1299.7208072540463,
            "y": 634.671457752373
          }
        }
      ],
      "edges": [
        {
          "source": "ConversationBufferMemory-frtJG",
          "sourceHandle": "{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-frtJGœ}",
          "target": "LLMChain-Pvm9x",
          "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "LLMChain-Pvm9x",
              "inputTypes": null,
              "type": "BaseMemory"
            },
            "sourceHandle": {
              "baseClasses": [
                "ConversationBufferMemory",
                "BaseChatMemory",
                "BaseMemory"
              ],
              "dataType": "ConversationBufferMemory",
              "id": "ConversationBufferMemory-frtJG"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ConversationBufferMemory-frtJG{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-frtJGœ}-LLMChain-Pvm9x{œfieldNameœ:œmemoryœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}"
        },
        {
          "source": "PromptTemplate-mrNIG",
          "sourceHandle": "{œbaseClassesœ:[œStringPromptTemplateœ,œPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-mrNIGœ}",
          "target": "LLMChain-Pvm9x",
          "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œPromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "prompt",
              "id": "LLMChain-Pvm9x",
              "inputTypes": null,
              "type": "PromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "StringPromptTemplate",
                "PromptTemplate",
                "BasePromptTemplate"
              ],
              "dataType": "PromptTemplate",
              "id": "PromptTemplate-mrNIG"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-PromptTemplate-mrNIG{œbaseClassesœ:[œStringPromptTemplateœ,œPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-mrNIGœ}-LLMChain-Pvm9x{œfieldNameœ:œpromptœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œPromptTemplateœ}"
        },
        {
          "source": "ChatOpenAI-qdmsI",
          "sourceHandle": "{œbaseClassesœ:[œChatOpenAIœ,œBaseChatModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-qdmsIœ}",
          "target": "LLMChain-Pvm9x",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-Pvm9x",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "ChatOpenAI",
                "BaseChatModel",
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "dataType": "ChatOpenAI",
              "id": "ChatOpenAI-qdmsI"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatOpenAI-qdmsI{œbaseClassesœ:[œChatOpenAIœ,œBaseChatModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-qdmsIœ}-LLMChain-Pvm9x{œfieldNameœ:œllmœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        }
      ],
      "viewport": {
        "x": -8.68396403367342,
        "y": 256.83423473981316,
        "zoom": 0.4060094549734929
      }
    },
    "description": "A simple chat with a custom prompt template and conversational memory buffer",
    "name": "Basic Chat with Prompt and History"
  }